import csv
import ollama
from ollama import Client
from sklearn.metrics import confusion_matrix, classification_report

client = Client()

"""
This program uses prompt engineering coupled with the few-shot learning method. The
model is asked to determine whether an image is persuasive or not in regards to gun control. No context is provided
within the prompt. The accuracy is recorded. Then, the model is provided with context within the
prompt (i.e. example images and their persuasiveness), and then asked to determine the persuasiveness of the same initial
images. The accuracy is recorded, and compared to the initial results.
"""

'''---FUNCTIONS---'''
#Function to interpret stance from the model response:
def interpretStance(llmOutput):
    llmOutput = llmOutput.lower()
    if "support" in llmOutput:
        return "support"
    return "oppose"

'''---UNTRAINED MODEL---'''
#Collect the image paths, as well as the image stances, for the query set:
queryPaths=[]
queryStances=[]
with open('Textual Tweet Training/Persuasive/Gun Control/GunControlPersuasiveQuery.csv', 'r') as file:
    csvReader = csv.reader(file)
    for tempRow in csvReader:
        queryPaths.append(tempRow[0])
        queryStances.append(tempRow[1])

#Without providing context, record the model's responses:
print("LLM Results Prior To Training:")
promptText="Determine if the following image is persuasive or not persuasive. Only respond with a single word: yes, no"

#Iterate through each query image, and find the result:
responseAr=[]
for tempPath in queryPaths:
  modelResponse = ollama.chat(
      model="llama3.2-vision",
      messages=[{
        "role": "user",
        "content": promptText,
        "images": [tempPath]
      }],
  )
  #Extract the model's response about the image:
  cleanedText = modelResponse['message']['content'].strip()
  stanceResp=interpretStance(cleanedText)
  responseAr.append(stanceResp)
  
#Calculate the accuracy:
amountCorrect=0
for tempInd in range(len(responseAr)):
    if(queryStances[tempInd]==responseAr[tempInd]):
        amountCorrect+=1

print("Accuracy: %"+str((amountCorrect/10)*100))

print("---")

'''---TRAINED MODEL---'''
print("Trained (Few-Shot) LLM Responses: ")
responseAr=[]

#Read all of the example image paths from the CSV file, along with the image stance:
imagePaths=[]
imageStance=[]
with open('Textual Tweet Training/Persuasive/Gun Control/GunControlPersuasiveTrain.csv', 'r') as file:
    csvReader = csv.reader(file)
    for tempRow in csvReader:
        imagePaths.append(tempRow[0])
        imageStance.append(tempRow[1])

#Produce a description for each of the training images:
descriptionStrings=""
for tempInd in range(len(imagePaths)):
    if imageStance[tempInd]=="yes":
        tempStr="is"
    else:
        tempStr="is not"

    modelResponse = ollama.chat(
        model="llama3.2-vision",
        messages=[{
            "role": "user",
            "content": "Please provide a description of the image in grammatically-correct, paragraph form, and explain how the image "+tempStr+" persuasive.",
            "images": [imagePaths[tempInd]]
        }],
    )
    cleanedText = modelResponse['message']['content'].strip()
    descriptionStrings+=cleanedText+"\n"

#After providing context with few-shot learning, provide the model's response:
promptText="Here are some image descriptions, as well as whether the image is persuasive or is not persuasive:\n"+descriptionStrings
promptText+="\nBased on the example image descriptions, determine if the following image is persuasive or is not persuasive. Only respond with a single word: yes, no"

#Use Ollama to analyze the image with Llama 3.2-Vision:
for tempPath in queryPaths:
  modelResponse = ollama.chat(
      model="llama3.2-vision",
      messages=[{
        "role": "user",
        "content": promptText,
        "images": [tempPath]
      }],
  )
  #Extract the model's response about the image:
  cleanedText = modelResponse['message']['content'].strip()
  stanceResp=interpretStance(cleanedText)
  responseAr.append(stanceResp)

#Calculate the accuracy:
amountCorrect=0
for tempInd in range(len(responseAr)):
    if(queryStances[tempInd]==responseAr[tempInd]):
        amountCorrect+=1

print("Accuracy: %"+str((amountCorrect/10)*100))
